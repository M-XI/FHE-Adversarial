{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-13 17:52:54 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
          ]
        }
      ],
      "source": [
        "from tqdm.auto import tqdm, trange\n",
        "import pickle\n",
        "import requests\n",
        "import json\n",
        "\n",
        "from abc import ABC\n",
        "from typing import List, Tuple, Callable, Dict\n",
        "from fairseq.hub_utils import GeneratorHubInterface\n",
        "from scipy.optimize import NonlinearConstraint, differential_evolution\n",
        "from textdistance import levenshtein\n",
        "import numpy as np\n",
        "\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "viWWjUc-HGoQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/ximic/.cache/torch/hub/pytorch_fairseq_main\n",
            "2024-04-13 17:52:59 | INFO | fairseq.file_utils | loading archive file https://dl.fbaipublicfiles.com/fairseq/models/wmt14.en-fr.joined-dict.transformer.tar.bz2 from cache at /home/ximic/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae\n",
            "2024-04-13 17:53:14 | INFO | fairseq.tasks.translation | [en] dictionary: 44512 types\n",
            "2024-04-13 17:53:14 | INFO | fairseq.tasks.translation | [fr] dictionary: 44512 types\n",
            "2024-04-13 17:53:18 | INFO | fairseq.models.fairseq_model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 2, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 128, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://learnfair0253:58342', 'distributed_port': 58342, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 5120, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 5120, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 80000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0007], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/checkpoint02/myleott/2018-05-19/wmt14_en_fr.fp16_allreduce.fp16.maxupd80000.transformer_vaswani_wmt_en_de_big.shareemb.adam.beta0.9,0.98.initlr1e-07.warmup4000.lr0.0007.clip0.0.drop0.1.wd0.0.ls0.1.maxtok5120.seed2.ngpu128', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 128}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=10, log_format='json', seed=2, data='/home/ximic/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae', source_lang='en', target_lang='fr', max_source_positions=1024, max_target_positions=1024, skip_invalid_size_inputs_valid_test=False, max_tokens=5120, max_sentences=None, train_subset='train', valid_subset='valid', max_sentences_valid=None, sample_without_replacement=0, distributed_world_size=128, distributed_rank=0, distributed_backend='nccl', distributed_init_method='tcp://learnfair0253:58342', distributed_port=58342, device_id=0, arch='transformer_vaswani_wmt_en_de_big', criterion='label_smoothed_cross_entropy', max_epoch=0, max_update=80000, clip_norm=0.0, sentence_avg=False, update_freq=[1.0], fp16=True, optimizer='adam', lr=[0.0007], momentum=0.99, weight_decay=0.0, lr_scheduler='inverse_sqrt', lr_shrink=0.1, save_dir='/checkpoint02/myleott/2018-05-19/wmt14_en_fr.fp16_allreduce.fp16.maxupd80000.transformer_vaswani_wmt_en_de_big.shareemb.adam.beta0.9,0.98.initlr1e-07.warmup4000.lr0.0007.clip0.0.drop0.1.wd0.0.ls0.1.maxtok5120.seed2.ngpu128', restore_file='checkpoint_last.pt', save_interval=1, no_save=False, no_epoch_checkpoints=False, validate_interval=1, dropout=0.1, attention_dropout=0.0, relu_dropout=0.0, encoder_normalize_before=False, encoder_learned_pos=False, decoder_learned_pos=False, decoder_normalize_before=False, share_decoder_input_output_embed=True, share_all_embeddings=True, label_smoothing=0.1, adam_betas='(0.9, 0.98)', adam_eps=1e-08, warmup_updates=4000, warmup_init_lr=1e-07, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layers=6, encoder_attention_heads=16, decoder_embed_dim=1024, decoder_ffn_embed_dim=4096, decoder_layers=6, decoder_attention_heads=16, tokenizer='moses', bpe='subword_nmt', bpe_codes='/home/ximic/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae/bpecodes', task='translation', stop_min_lr=1e-09, _name='transformer_vaswani_wmt_en_de_big', encoder_embed_path=None, decoder_embed_path=None, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0), 'task': {'_name': 'translation', 'data': '/home/ximic/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae', 'source_lang': 'en', 'target_lang': 'fr', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0007]}, 'scoring': None, 'bpe': {'_name': 'subword_nmt', 'bpe_codes': '/home/ximic/.cache/torch/pytorch_fairseq/53f403ba27ab138b06c1a8d78f5bb4f1722567ac3d3b3e41f821ec2cae2974da.7ef8ab763efda16d3c82dd8b5a574bdfe524e078bac7b444ea1a9c5d355b55ae/bpecodes', 'bpe_separator': '@@'}, 'tokenizer': {'_name': 'moses', 'source_lang': 'en', 'target_lang': 'fr', 'moses_no_dash_splits': False, 'moses_no_escape': False}, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained translation model\n",
        "en2fr = torch.hub.load('pytorch/fairseq',\n",
        "                       'transformer.wmt14.en-fr',\n",
        "                       tokenizer='moses',\n",
        "                       bpe='subword_nmt').cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYQox9UdXuhk"
      },
      "source": [
        "## Unknown Characters\n",
        "\n",
        "Unusual characters, such as zero-width spaces and control sequences, are simply encoded as the `<unk>` character by the FairSeq implementation. This likely generalizes to many other NLP models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WEeuVyV3Gl9H"
      },
      "outputs": [],
      "source": [
        "# Define function for decoding from the source dictionary\n",
        "def src_decode(sentence):\n",
        "  res = []\n",
        "  for idx in sentence:\n",
        "    res.append(en2fr.src_dict.symbols[idx])\n",
        "  return ' '.join(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiqHqng-jFTp"
      },
      "source": [
        "## Invisible Characters\n",
        "\n",
        "Certian Unicode chacacters are almost never visually rendered by design. Conveniently, they can be embedded within strings and copied + pasted on most systems. Most NLP models are not trained against these characters, making them  not present in source language dictionaries. Thus, they typically result in an `<unk>` embedded vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgnxrZhEj-bj",
        "outputId": "aae80038-f1c8-409d-def4-36bc3e584dce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "​‍\n"
          ]
        }
      ],
      "source": [
        "# Zero width space\n",
        "ZWSP = chr(0x200B)\n",
        "# Zero width joiner\n",
        "ZWJ = chr(0x200D)\n",
        "# Zero width non-joiner\n",
        "ZWNJ = chr(0x200C)\n",
        "\n",
        "print(f\"{ZWSP}{ZWJ}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niuB-qIcaV97"
      },
      "source": [
        "## Homoglyphs\n",
        "\n",
        "The Unicode specification defines several homoglyph documents. The following section retrieves these documents and creates mapping between homoglyph characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4f_QLoIraVM6"
      },
      "outputs": [],
      "source": [
        "confusables = dict()\n",
        "intentionals = dict()\n",
        "\n",
        "# Retrieve Unicode Confusable homoglyph characters\n",
        "conf_resp = requests.get(\"https://www.unicode.org/Public/security/latest/confusables.txt\", stream=True)\n",
        "for line in conf_resp.iter_lines():\n",
        "  if len(line):\n",
        "    line = line.decode('utf-8-sig')\n",
        "    if line[0] != '#':\n",
        "      line = line.replace(\"#*\", \"#\")\n",
        "      _, line = line.split(\"#\", maxsplit=1)\n",
        "      if line[3] not in confusables:\n",
        "        confusables[line[3]] = []\n",
        "      confusables[line[3]].append(line[7])\n",
        "\n",
        "# Retrieve Unicode Intentional homoglyph characters\n",
        "int_resp = requests.get(\"https://www.unicode.org/Public/security/latest/intentional.txt\", stream=True)\n",
        "for line in int_resp.iter_lines():\n",
        "  if len(line):\n",
        "    line = line.decode('utf-8-sig')\n",
        "    if line[0] != '#':\n",
        "      line = line.replace(\"#*\", \"#\")\n",
        "      _, line = line.split(\"#\", maxsplit=1)\n",
        "      if line[3] not in intentionals:\n",
        "        intentionals[line[3]] = []\n",
        "      intentionals[line[3]].append(line[7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAKEobGSg73m"
      },
      "source": [
        "## Reorderings\n",
        "\n",
        "Unicode Bidirectional (Bidi) Algorithm override characters can be used to render encodeded characters in any order. The following section defines a function which can generate 2^|n| reordered encodings of a given string of length n which are all rendered the same way in any system built on Google's Chromium.\n",
        "\n",
        "This [site](https://www.soscisurvey.de/tools/view-chars.php) can be used to visualize the underlying encoding of the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TyYumqPphwPT"
      },
      "outputs": [],
      "source": [
        "# Unicode Bidi override characters\n",
        "PDF = chr(0x202C)\n",
        "LRE = chr(0x202A)\n",
        "RLE = chr(0x202B)\n",
        "LRO = chr(0x202D)\n",
        "RLO = chr(0x202E)\n",
        "\n",
        "PDI = chr(0x2069)\n",
        "LRI = chr(0x2066)\n",
        "RLI = chr(0x2067)\n",
        "\n",
        "class Swap():\n",
        "    \"\"\"Represents swapped elements in a string of text.\"\"\"\n",
        "    def __init__(self, one, two):\n",
        "        self.one = one\n",
        "        self.two = two\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return f\"Swap({self.one}, {self.two})\"\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        return self.one == other.one and self.two == other.two\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self.one, self.two))\n",
        "\n",
        "def some(*els):\n",
        "    \"\"\"Returns the arguments as a tuple with Nones removed.\"\"\"\n",
        "    return tuple(filter(None, tuple(els)))\n",
        "\n",
        "def swaps(chars: str) -> set:\n",
        "    \"\"\"Generates all possible swaps for a string.\"\"\"\n",
        "    def pairs(chars, pre=(), suf=()):\n",
        "        orders = set()\n",
        "        for i in range(len(chars)-1):\n",
        "            prefix = pre + tuple(chars[:i])\n",
        "            suffix = suf + tuple(chars[i+2:])\n",
        "            swap = Swap(chars[i+1], chars[i])\n",
        "            pair = some(prefix, swap, suffix)\n",
        "            orders.add(pair)\n",
        "            orders.update(pairs(suffix, pre=some(prefix, swap)))\n",
        "            orders.update(pairs(some(prefix, swap), suf=suffix))\n",
        "        return orders\n",
        "    return pairs(chars) | {tuple(chars)}\n",
        "\n",
        "def unswap(el: tuple) -> str:\n",
        "    \"\"\"Reverts a tuple of swaps to the original string.\"\"\"\n",
        "    if isinstance(el, str):\n",
        "        return el\n",
        "    elif isinstance(el, Swap):\n",
        "        return unswap((el.two, el.one))\n",
        "    else:\n",
        "        res = \"\"\n",
        "        for e in el:\n",
        "            res += unswap(e)\n",
        "        return res\n",
        "\n",
        "def uniswap(els):\n",
        "    res = \"\"\n",
        "    for el in els:\n",
        "        if isinstance(el, Swap):\n",
        "            res += uniswap([LRO, LRI, RLO, LRI, el.one, PDI, LRI, el.two, PDI, PDF, PDI, PDF])\n",
        "        elif isinstance(el, str):\n",
        "            res += el\n",
        "        else:\n",
        "            for subel in el:\n",
        "                res += uniswap([subel])\n",
        "    return res\n",
        "\n",
        "def strings_to_file(file, string):\n",
        "  with open(file, 'w') as f:\n",
        "      for swap in swaps(string):\n",
        "          uni = uniswap(swap)\n",
        "          print(uni, file=f)\n",
        "\n",
        "def print_strings(string):\n",
        "  for swap in swaps(string):\n",
        "    uni = uniswap(swap)\n",
        "    print(uni)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T8jtEdBkzTn"
      },
      "source": [
        "## Deletions\n",
        "\n",
        "Unicode control characters used for deleting text can be encoded into strings. Upon rendering, these control characters are actioned and the appropriate surrounding text is not rendered. Yet, NLP models generally still \"see\" the surrounding text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-5sEX6PlbDH",
        "outputId": "2544b8f2-4589-4386-be88-562f6eb4659b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Backspace character\n",
        "BKSP = chr(0x8)\n",
        "# Delete character\n",
        "DEL = chr(0x7F)\n",
        "# Carriage return character\n",
        "CR = chr(0xD)\n",
        "\n",
        "print(f\"{CR}{BKSP}{DEL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojTrDJ1oobLo"
      },
      "source": [
        "## Untargeted Integrity Attacks\n",
        "\n",
        "The performance of various NLP models can be degraded through the use of invisible character, homoglyph, reordering, and deletion attacks. The most effective attacks can be found, independent of the underlying model, using a genetic algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpQCNy1ub-xr"
      },
      "source": [
        "### Attack Setup\n",
        "\n",
        "Each attack will be defined as an object and set of contstraints over which a genetic algorithm (differential evolution) will optimize. For these attacks, the visual representation of the input is fixed and the aim of the attack is to determine the imperceptible perturbation for which the supplied model's output will be maximally distant from the output of the unperturbed input.\n",
        "\n",
        "Each attack will be derived from the following Objective abstract class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sV06ofK0o8uf"
      },
      "outputs": [],
      "source": [
        "class Objective(ABC):\n",
        "  \"\"\" Abstract class representing objectives for scipy's genetic algorithms.\"\"\"\n",
        "\n",
        "  def __init__(self, model: GeneratorHubInterface, input: str, max_perturbs: int, distance: Callable[[str,str],int]):\n",
        "    if not model:\n",
        "      raise ValueError(\"Must supply model.\")\n",
        "    if not input:\n",
        "      raise ValueError(\"Must supply input.\")\n",
        "\n",
        "    self.model: GeneratorHubInterface = model\n",
        "    self.input: str = input\n",
        "    self.max_perturbs: int = max_perturbs\n",
        "    self.distance: Callable[[str,str],int] = distance\n",
        "    self.output = self.model.translate(self.input)\n",
        "\n",
        "  def objective(self) -> Callable[[List[float]], float]:\n",
        "    def _objective(perturbations: List[float]) -> float:\n",
        "      candidate: str = self.candidate(perturbations)\n",
        "      translation: str = self.model.translate(candidate)\n",
        "      return -self.distance(self.output, translation)\n",
        "    return _objective\n",
        "\n",
        "  def differential_evolution(self, print_result=True, verbose=True, maxiter=60, popsize=32, polish=False) -> str:\n",
        "    result = differential_evolution(self.objective(), self.bounds(),\n",
        "                                    disp=verbose, maxiter=maxiter,\n",
        "                                    popsize=popsize, polish=polish)\n",
        "    candidate = self.candidate(result.x)\n",
        "    if (print_result):\n",
        "      print(f\"Result: {candidate}\")\n",
        "      print(f\"Result Distance: {result.fun}\")\n",
        "      print(f\"Perturbation Encoding: {result.x}\")\n",
        "      print(f\"Input Translation: {self.output}\")\n",
        "      print(f\"Result Translation: {self.model.translate(candidate)}\")\n",
        "    return candidate\n",
        "\n",
        "  def bounds(self) -> List[Tuple[float, float]]:\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def candidate(self, perturbations: List[float]) -> str:\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def natural(x: float) -> int:\n",
        "    \"\"\"Rounds float to the nearest natural number (positive int)\"\"\"\n",
        "    return max(0, round(float(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5httsCzjV2tf"
      },
      "outputs": [],
      "source": [
        "class InvisibleCharacterObjective(Objective):\n",
        "  \"\"\"Class representing an Objective which injects invisible characters.\"\"\"\n",
        "\n",
        "  def __init__(self, model: GeneratorHubInterface, input: str, max_perturbs: int = 25, invisible_chrs: List[str] = [ZWJ,ZWSP,ZWNJ], distance: Callable[[str,str],int] = levenshtein.distance, **kwargs):\n",
        "    super().__init__(model, input, max_perturbs, distance)\n",
        "    self.invisible_chrs: List[str] = invisible_chrs\n",
        "\n",
        "  def bounds(self) -> List[Tuple[float, float]]:\n",
        "    return [(0,len(self.invisible_chrs)-1), (-1, len(self.input)-1)] * self.max_perturbs\n",
        "\n",
        "  def candidate(self, perturbations: List[float]) -> str:\n",
        "    candidate = [char for char in self.input]\n",
        "    for i in range(0, len(perturbations), 2):\n",
        "      inp_index = natural(perturbations[i+1])\n",
        "      if inp_index >= 0:\n",
        "        inv_char = self.invisible_chrs[natural(perturbations[i])]\n",
        "        candidate = candidate[:inp_index] + [inv_char] + candidate[inp_index:]\n",
        "    return ''.join(candidate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MLc8fWVBddkv"
      },
      "outputs": [],
      "source": [
        "class HomoglyphObjective(Objective):\n",
        "\n",
        "  def __init__(self, model: GeneratorHubInterface, input: str, max_perturbs=None, distance: Callable[[str,str],int] = levenshtein.distance, homoglyphs: Dict[str,List[str]] = intentionals, **kwargs):\n",
        "    super().__init__(model, input, max_perturbs, distance)\n",
        "    if not self.max_perturbs:\n",
        "      self.max_perturbs = len(self.input)\n",
        "    self.homoglyphs = homoglyphs\n",
        "    self.glyph_map = []\n",
        "    for i, char in enumerate(self.input):\n",
        "      if char in self.homoglyphs:\n",
        "        charmap = self.homoglyphs[char]\n",
        "        charmap = list(zip([i] * len(charmap), charmap))\n",
        "        self.glyph_map.extend(charmap)\n",
        "\n",
        "  def bounds(self) -> List[Tuple[float, float]]:\n",
        "    return [(-1, len(self.glyph_map)-1)] * self.max_perturbs\n",
        "\n",
        "  def candidate(self, perturbations: List[float]) -> str:\n",
        "    candidate = [char for char in self.input]  \n",
        "    for perturb in map(natural, perturbations):\n",
        "      if perturb >= 0:\n",
        "        i, char = self.glyph_map[perturb]\n",
        "        candidate[i] = char\n",
        "    return ''.join(candidate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gJ7lK8RDeAb9"
      },
      "outputs": [],
      "source": [
        "class ReorderObjective(Objective):\n",
        "\n",
        "  def __init__(self, model: GeneratorHubInterface, input: str, max_perturbs: int = 50, distance: Callable[[str,str],int] = levenshtein.distance, **kwargs):\n",
        "    super().__init__(model, input, max_perturbs, distance)\n",
        "\n",
        "  def bounds(self) -> List[Tuple[float, float]]:\n",
        "    return [(-1,len(self.input)-1)] * self.max_perturbs\n",
        "\n",
        "  def candidate(self, perturbations: List[float]) -> str:\n",
        "    def swaps(els) -> str:\n",
        "      res = \"\"\n",
        "      for el in els:\n",
        "          if isinstance(el, Swap):\n",
        "              res += swaps([LRO, LRI, RLO, LRI, el.one, PDI, LRI, el.two, PDI, PDF, PDI, PDF])\n",
        "          elif isinstance(el, str):\n",
        "              res += el\n",
        "          else:\n",
        "              for subel in el:\n",
        "                  res += swaps([subel])\n",
        "      return res\n",
        "\n",
        "    _candidate = [char for char in self.input]\n",
        "    for perturb in map(natural, perturbations):\n",
        "      if perturb >= 0 and len(_candidate) >= 2:\n",
        "        perturb = min(perturb, len(_candidate) - 2)\n",
        "        _candidate = _candidate[:perturb] + [Swap(_candidate[perturb+1], _candidate[perturb])] + _candidate[perturb+2:]\n",
        "\n",
        "    return swaps(_candidate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7S0ilPknepk-"
      },
      "outputs": [],
      "source": [
        "class DeletionObjective(Objective):\n",
        "  \"\"\"Class representing an Objective which injects deletion control characters.\"\"\"\n",
        "\n",
        "  def __init__(self, model: GeneratorHubInterface, input: str, max_perturbs: int = 100, distance: Callable[[str,str],int] = levenshtein.distance, del_chr: str = BKSP, ins_chr_min: str = '!', ins_chr_max: str = '~', **kwargs):\n",
        "    super().__init__(model, input, max_perturbs, distance)\n",
        "    self.del_chr: str = del_chr\n",
        "    self.ins_chr_min: str = ins_chr_min\n",
        "    self.ins_chr_max: str = ins_chr_max\n",
        "\n",
        "  def bounds(self) -> List[Tuple[float, float]]:\n",
        "    return [(-1,len(self.input)-1), (ord(self.ins_chr_min),ord(self.ins_chr_max))] * self.max_perturbs\n",
        "\n",
        "  def candidate(self, perturbations: List[float]) -> str:\n",
        "    candidate = [char for char in self.input]\n",
        "    for i in range(0, len(perturbations), 2):\n",
        "      idx = natural(perturbations[i])\n",
        "      char = chr(natural(perturbations[i+1]))\n",
        "      candidate = candidate[:idx] + [char, self.del_chr] + candidate[idx:]\n",
        "      for j in range(i,len(perturbations), 2):\n",
        "        perturbations[j] += 2\n",
        "    return ''.join(candidate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSPzj7hCqUil"
      },
      "source": [
        "### SST2 Attacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJUcSFQoq4TH"
      },
      "source": [
        "#### Attack Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HhCUHc9wD5Kz"
      },
      "outputs": [],
      "source": [
        "# !wget https://cims.nyu.edu/~sbowman/multinli/multinli_1.0.zip\n",
        "# !unzip multinli_1.0.zip\n",
        "# !rm -rf __MACOSX/\n",
        "\n",
        "# with open('multinli_1.0/multinli_1.0_dev_matched.jsonl', 'r') as f:\n",
        "#   mnli_test = [json.loads(jline) for jline in f.readlines()]\n",
        "\n",
        "# Load pre-trained translation model\n",
        "# mnli = torch.hub.load('pytorch/fairseq',\n",
        "#                        'roberta.large.mnli').eval().cuda()\n",
        "# label_map = {'contradiction': 0, 'neutral': 1, 'entailment': 2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hDuuIfqeD9Zb"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import PreTrainedTokenizer, PreTrainedModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./sst2_gpt2\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./sst2_gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9fp6z8AQJ1xT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-13 17:53:34 | INFO | datasets | PyTorch version 1.13.1 available.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'idx': 0, 'sentence': \"it 's a charming and often affecting journey . \", 'label': 1}, {'idx': 1, 'sentence': 'unflinchingly bleak and desperate ', 'label': 0}, {'idx': 2, 'sentence': 'allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker . ', 'label': 1}]\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"sst2\")[\"validation\"]\n",
        "dataset = dataset.to_dict()\n",
        "dataset = [dict(zip(dataset, t)) for t in zip(*dataset.values())]\n",
        "print(dataset[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[1212,  318,  257, 1332,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n",
            "tensor([-0.1196,  0.0964], grad_fn=<SqueezeBackward0>)\n"
          ]
        }
      ],
      "source": [
        "test_input = tokenizer(\"This is a test!\", return_tensors='pt')\n",
        "print(test_input)\n",
        "test_pred = model(**test_input)\n",
        "print(test_pred.logits.squeeze())\n",
        "\n",
        "sst2_model = (tokenizer, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_budget = 1\n",
        "max_budget = min_budget + 1\n",
        "iterations = 2\n",
        "population = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BSuP_CV4LhJB"
      },
      "outputs": [],
      "source": [
        "class SST2Objective():\n",
        "\n",
        "  def __init__(self, model: tuple[PreTrainedTokenizer, PreTrainedModel], input: str, label: int, max_perturbs: int):\n",
        "    if not model:\n",
        "      raise ValueError(\"Must supply model.\")\n",
        "    if not input:\n",
        "      raise ValueError(\"Must supply input.\")\n",
        "    if label == None:\n",
        "      raise ValueError(\"Must supply label.\")\n",
        "    self.model: tuple[PreTrainedTokenizer, PreTrainedModel] = model\n",
        "    self.input: str = input\n",
        "    self.label: int = label\n",
        "    self.max_perturbs: int = max_perturbs\n",
        "\n",
        "  def objective(self) -> Callable[[List[float]], float]:\n",
        "    def _objective(perturbations: List[float]) -> float:\n",
        "      candidate: str = self.candidate(perturbations)\n",
        "      tokens = self.model[0](candidate, return_tensors=\"pt\")\n",
        "      predict = self.model[1](**tokens).logits.squeeze()\n",
        "      if predict.argmax() != self.label:\n",
        "        return -np.inf\n",
        "      else:\n",
        "        return predict.cpu().detach().numpy()[self.label]\n",
        "    return _objective\n",
        "\n",
        "  def differential_evolution(self, print_result=True, verbose=True, maxiter=3, popsize=32, polish=False) -> str:\n",
        "    result = differential_evolution(self.objective(), self.bounds(),\n",
        "                                    disp=verbose, maxiter=maxiter,\n",
        "                                    popsize=popsize, polish=polish)\n",
        "    candidate = self.candidate(result.x)\n",
        "    if (print_result):\n",
        "      print(f\"Result: {candidate}\")\n",
        "      print(f\"Correct Label Prediction: {result.fun}\")\n",
        "      print(f\"Perturbation Encoding: {result.x}\")\n",
        "    return candidate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahA_kEqirIYs"
      },
      "source": [
        "#### Invisible Character Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oHURE2Ueoy_b"
      },
      "outputs": [],
      "source": [
        "class InvisibleCharacterMnliObjective(SST2Objective, InvisibleCharacterObjective):\n",
        "  \n",
        "  def __init__(self, model: tuple[PreTrainedTokenizer, PreTrainedModel], \n",
        "                     input: str, label:int, max_perturbs: int = 10, invisible_chrs: List[str] = [ZWJ,ZWSP,ZWNJ], **kwargs):\n",
        "    super().__init__(model, input, label, max_perturbs)\n",
        "    self.invisible_chrs = invisible_chrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUP4a9g6rDCO"
      },
      "source": [
        "#### Homoglyph Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "itVYlZ8cWAzT"
      },
      "outputs": [],
      "source": [
        "class HomoglyphMnliObjective(SST2Objective, HomoglyphObjective):\n",
        "  \n",
        "  def __init__(self, model: tuple[PreTrainedTokenizer, PreTrainedModel], \n",
        "                     input: str, label:int, max_perturbs: int = 10, homoglyphs: Dict[str,List[str]] = intentionals, **kwargs):\n",
        "    super().__init__(model, input, label, max_perturbs)\n",
        "    self.homoglyphs = homoglyphs\n",
        "    self.glyph_map = []\n",
        "    for i, char in enumerate(self.input):\n",
        "      if char in self.homoglyphs:\n",
        "        charmap = self.homoglyphs[char]\n",
        "        charmap = list(zip([i] * len(charmap), charmap))\n",
        "        self.glyph_map.extend(charmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBTXc26wzXFm"
      },
      "source": [
        "#### Reordering Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "e0dovztEzgOK"
      },
      "outputs": [],
      "source": [
        "class ReorderMnliObjective(SST2Objective, ReorderObjective):\n",
        "  \n",
        "  def __init__(self, model: tuple[PreTrainedTokenizer, PreTrainedModel], \n",
        "                     input: str, label:int, max_perturbs: int = 10, **kwargs):\n",
        "    super().__init__(model, input, label, max_perturbs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtbaskhQ07Pp"
      },
      "source": [
        "#### Deletion Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "z5ueORGu0-9B"
      },
      "outputs": [],
      "source": [
        "class DeletionMnliObjective(SST2Objective, DeletionObjective):\n",
        "  \n",
        "  def __init__(self, model: tuple[PreTrainedTokenizer, PreTrainedModel], \n",
        "                     input: str, label:int, max_perturbs: int = 10, del_chr: str = BKSP, ins_chr_min: str = '!', ins_chr_max: str = '~', **kwargs):\n",
        "    super().__init__(model, input, label, max_perturbs)\n",
        "    self.del_chr: str = del_chr\n",
        "    self.ins_chr_min: str = ins_chr_min\n",
        "    self.ins_chr_max: str = ins_chr_max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZXEUjBXrZc9"
      },
      "source": [
        "#### Attack Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3YuRw65sSNs"
      },
      "source": [
        "##### Experiment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KJ6D_CRKWhGv"
      },
      "outputs": [],
      "source": [
        "def sst2_experiment(model, objective, data, file, min_budget, max_budget, maxiter, popsize):\n",
        "  perturbs = { '0': data }\n",
        "  for budget in trange(min_budget, max_budget):\n",
        "    perturbs[str(budget)] = dict()\n",
        "    for test in tqdm(data, leave=False):\n",
        "      obj = objective(model, test[\"sentence\"], test[\"label\"])\n",
        "      example = obj.differential_evolution(print_result=False, verbose=False, maxiter=maxiter, popsize=popsize)\n",
        "      perturbs[str(budget)][test[\"idx\"]] = example\n",
        "      with open(file, 'wb') as f:\n",
        "          pickle.dump(perturbs, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhiXUU3ns7tb"
      },
      "source": [
        "##### Invisible Character Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "lyDKrYGQs93H"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e2a1184188743008743f655e02fefbf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a978592511fb442c8196f52078301648",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sst2_experiment(sst2_model, InvisibleCharacterMnliObjective, dataset[:20], \"sst2_invisible_chars.pkl\", min_budget, max_budget, iterations, population)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otR1as3grcYd"
      },
      "source": [
        "##### Homoglyph Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sVYje4ImdWcV"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60f66760c6334bb1a7f2ca17e5fcbf8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31292a436dc24c84ae87dffb07bf6743",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sst2_experiment(sst2_model, HomoglyphMnliObjective, dataset[:20], \"sst2_homoglyphs.pkl\", min_budget, max_budget, iterations, population)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybl3kRdo0gjc"
      },
      "source": [
        "##### Reordering Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tzNJAO0t0jfI"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7ab3d3b374449deb08cf277ca6168c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba18d11b24f24310829abafc2c8dd619",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sst2_experiment(sst2_model, ReorderMnliObjective, dataset[:20], \"sst2_reorder.pkl\", min_budget, max_budget, iterations, population)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROInHhWz0wL7"
      },
      "source": [
        "##### Deletion Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Q5tHz73o0ykV"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c59abaf4a6e4e4bb0fd1f3ca445e09a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "609b19e0b04e4c2ebaaaf74b99038f61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sst2_experiment(sst2_model, DeletionMnliObjective, dataset[:20], \"sst2_deletion.pkl\", min_budget, max_budget, iterations, population)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzkaxO-WfZU2"
      },
      "source": [
        "## Targeted Integrity Attacks\n",
        "\n",
        "Targeted imperceptible perturbation attacks craft imperceptible perturbations for a given input that attempt to produce a fixed output against a given model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8uy-ZXgkqeq"
      },
      "source": [
        "### SST2 Targeted Attack\n",
        "\n",
        "These attacks target the SST2 sentiment classification task in a black box model that does have access to the resulting logits for each class during inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xMWQl6PkwTr"
      },
      "source": [
        "#### Experiment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qh9gMc9ynWb6"
      },
      "outputs": [],
      "source": [
        "from torch.nn.functional import softmax\n",
        "\n",
        "class SST2TargetedObjective(SST2Objective):\n",
        "\n",
        "  def __init__(self, model: tuple[PreTrainedTokenizer, PreTrainedModel], \n",
        "                     input: str, label: int, target: int, max_perturbs: int):\n",
        "    super().__init__(model, input, label, max_perturbs)\n",
        "    self.target = target\n",
        "\n",
        "  def objective(self) -> Callable[[List[float]], float]:\n",
        "      def _objective(perturbations: List[float]) -> float:\n",
        "        candidate: str = self.candidate(perturbations)\n",
        "        tokens = self.model[0](candidate, return_tensors=\"pt\")\n",
        "        predict = self.model[1](**tokens).logits.squeeze()\n",
        "        return -softmax(predict).cpu().detach().numpy()[self.target]\n",
        "      return _objective\n",
        "\n",
        "  def differential_evolution(self, print_result=True, verbose=True, maxiter=3, popsize=32, polish=False) -> str:\n",
        "    result = differential_evolution(self.objective(), self.bounds(),\n",
        "                                    disp=verbose, maxiter=maxiter,\n",
        "                                    popsize=popsize, polish=polish)\n",
        "    candidate = self.candidate(result.x)\n",
        "    if (print_result):\n",
        "      print(f\"Result: {candidate}\")\n",
        "      print(f\"Correct Label Prediction: {result.fun}\")\n",
        "      print(f\"Perturbation Encoding: {result.x}\")\n",
        "    return candidate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0V33hDWkzpx"
      },
      "source": [
        "#### Invisible Character Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "etxYIQHWvWBg"
      },
      "outputs": [],
      "source": [
        "class InvisibleCharacterTargetedSST2Objective(SST2TargetedObjective, InvisibleCharacterObjective):\n",
        "  \n",
        "  def __init__(self, model: tuple[PreTrainedTokenizer, PreTrainedModel], \n",
        "                     input: str, label:int, target: int, max_perturbs: int = 10, invisible_chrs: List[str] = [ZWJ,ZWSP,ZWNJ], **kwargs):\n",
        "    super().__init__(model, input, label, target, max_perturbs)\n",
        "    self.invisible_chrs = invisible_chrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccSPOXLwk2dj"
      },
      "source": [
        "#### Homoglyph Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BTE0No5no2H_"
      },
      "outputs": [],
      "source": [
        "class HomoglyphTargetedSST2Objective(SST2TargetedObjective, HomoglyphObjective):\n",
        "  \n",
        "  def __init__(self, model: tuple[PreTrainedTokenizer, PreTrainedModel], \n",
        "                     input: str, label:int, target: int, max_perturbs: int = 10, homoglyphs: Dict[str,List[str]] = intentionals, **kwargs):\n",
        "    super().__init__(model, input, label, target, max_perturbs)\n",
        "    self.homoglyphs = homoglyphs\n",
        "    self.glyph_map = []\n",
        "    for i, char in enumerate(self.input):\n",
        "      if char in self.homoglyphs:\n",
        "        charmap = self.homoglyphs[char]\n",
        "        charmap = list(zip([i] * len(charmap), charmap))\n",
        "        self.glyph_map.extend(charmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH-oHYh3k4eU"
      },
      "source": [
        "#### Reordering Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Wa4XDoP9qroW"
      },
      "outputs": [],
      "source": [
        "class ReorderTargetedSST2Objective(SST2TargetedObjective, ReorderObjective):\n",
        "  \n",
        "  def __init__(self, model: tuple[PreTrainedTokenizer, PreTrainedModel], \n",
        "                     input: str, label:int, target: int, max_perturbs: int = 10, **kwargs):\n",
        "    super().__init__(model, input, label, target, max_perturbs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJKj4qB4lEuZ"
      },
      "source": [
        "#### Deletion Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bqhE55exrKhN"
      },
      "outputs": [],
      "source": [
        "class DeletionTargetedSST2Objective(SST2TargetedObjective, DeletionObjective):\n",
        "  \n",
        "  def __init__(self, model: tuple[PreTrainedTokenizer, PreTrainedModel], \n",
        "                     input: str, label:int, target: int, max_perturbs: int = 10, del_chr: str = BKSP, ins_chr_min: str = '!', ins_chr_max: str = '~', **kwargs):\n",
        "    super().__init__(model, input, label, target, max_perturbs)\n",
        "    self.del_chr = del_chr\n",
        "    self.ins_chr_min: str = ins_chr_min\n",
        "    self.ins_chr_max: str = ins_chr_max"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heDGljGynpvW"
      },
      "source": [
        "#### Attack Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOeTGoWbntSG"
      },
      "source": [
        "##### Experiment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Ft3K4MMansUf"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from time import process_time\n",
        "import pickle\n",
        "\n",
        "def sst2_targeted_experiment(objective, model, label_map, inputs, file, min_budget = min_budget, max_budget = max_budget, maxiter = iterations, popsize = population):\n",
        "  results = { '0': inputs }\n",
        "  with tqdm(total=len(inputs)*(max_budget-min_budget+1)*len(label_map), desc=\"Adv. Examples\") as pbar:\n",
        "    for budget in range(min_budget, max_budget+1):\n",
        "      results[str(budget)] = {}\n",
        "      for input in inputs:\n",
        "        results[str(budget)][input[\"idx\"]] = []\n",
        "        for label in range(len(label_map)):\n",
        "          obj = objective(model, input[\"sentence\"], input[\"label\"], label, max_perturbs=budget)\n",
        "          candidate = obj.differential_evolution(print_result=False, verbose=False, maxiter=maxiter, popsize=popsize)\n",
        "          results[str(budget)][input[\"idx\"]].append(candidate)\n",
        "          with open(file, 'wb') as f:\n",
        "            pickle.dump(results, f)\n",
        "          pbar.update(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIxaZcoun8Yr"
      },
      "source": [
        "##### Invisible Character Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "e3c_ciBqn-Yz"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "808cd48b32224fffa4fe6a8decd5d160",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Adv. Examples:   0%|          | 0/80 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_25561/1737927288.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return -softmax(predict).cpu().detach().numpy()[self.target]\n"
          ]
        }
      ],
      "source": [
        "sst2_targeted_experiment(InvisibleCharacterTargetedSST2Objective, sst2_model, [0, 1], dataset[:20], \"sst2_invisibles_targeted.pkl\", maxiter=iterations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEsD6pNxoApH"
      },
      "source": [
        "##### Homoglyph Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Ip6gCE5KoKbH"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccad89f2c70f4138be39b743246437e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Adv. Examples:   0%|          | 0/80 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_25561/1737927288.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return -softmax(predict).cpu().detach().numpy()[self.target]\n"
          ]
        }
      ],
      "source": [
        "sst2_targeted_experiment(HomoglyphTargetedSST2Objective, sst2_model, [0, 1], dataset[:20], \"sst2_homoglyphs_targeted.pkl\", maxiter=iterations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S1EjfLToHGt"
      },
      "source": [
        "##### Redordering Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "UfdYFNK4oMi9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "557bfd5c23e34201acf32e288fc871e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Adv. Examples:   0%|          | 0/80 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_25561/1737927288.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return -softmax(predict).cpu().detach().numpy()[self.target]\n"
          ]
        }
      ],
      "source": [
        "sst2_targeted_experiment(ReorderTargetedSST2Objective, sst2_model, [0, 1], dataset[:20], \"sst2_reorderings_targeted.pkl\", maxiter=iterations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qewUL_MSoDRe"
      },
      "source": [
        "##### Deletion Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "0SOY1oXqoPiH"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b812bd9d1b8241678aca63f0186df0b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Adv. Examples:   0%|          | 0/80 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_25561/1737927288.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return -softmax(predict).cpu().detach().numpy()[self.target]\n"
          ]
        }
      ],
      "source": [
        "sst2_targeted_experiment(DeletionTargetedSST2Objective, sst2_model, [0, 1], dataset[:20], \"sst2_deletions_targeted.pkl\", maxiter=iterations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uexNQ2g0lcDh"
      },
      "source": [
        "### SST2 (No Logits) Targeted Attack\n",
        "\n",
        "This attack is identical to the SST2 targeted attack except that the adversary only has access to the predicted class and does not have access to the resulting logits for each class during inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgjtSgwPlvC_"
      },
      "source": [
        "#### Attack Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Wpwr5NpKXk47"
      },
      "outputs": [],
      "source": [
        "class SST2TargetedNoLogitsObjective(SST2TargetedObjective):\n",
        "\n",
        "  def objective(self) -> Callable[[List[float]], float]:\n",
        "      def _objective(perturbations: List[float]) -> float:\n",
        "        candidate: str = self.candidate(perturbations)\n",
        "        tokens = self.model[0](candidate, return_tensors=\"pt\")\n",
        "        predict = self.model[1](**tokens).logits.squeeze()\n",
        "        if predict.argmax().item() == self.target:\n",
        "          return -np.inf\n",
        "        else:\n",
        "          return np.inf\n",
        "      return _objective"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqumdYGQl1XY"
      },
      "source": [
        "#### Invisible Character Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "7EMGh4fWYQXC"
      },
      "outputs": [],
      "source": [
        "class InvisibleCharacterTargetedSST2NoLogitsObjective(SST2TargetedNoLogitsObjective, InvisibleCharacterTargetedSST2Objective):\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKuYC1ZGl333"
      },
      "source": [
        "#### Homoglyph Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "X1tx1yz-YaR8"
      },
      "outputs": [],
      "source": [
        "class HomoglyphTargetedSST2NoLogitsObjective(SST2TargetedNoLogitsObjective, HomoglyphTargetedSST2Objective):\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coli97Usl5pU"
      },
      "source": [
        "#### Reordering Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "lTDUg67WYzH8"
      },
      "outputs": [],
      "source": [
        "class ReorderTargetedSST2NoLogitsObjective(SST2TargetedNoLogitsObjective, ReorderTargetedSST2Objective):\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FEs8Ggfl9Iq"
      },
      "source": [
        "#### Deletion Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "WLbur_VxY4bL"
      },
      "outputs": [],
      "source": [
        "class DeletionTargetedSST2NoLogitsObjective(SST2TargetedNoLogitsObjective, DeletionTargetedSST2Objective):\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szN7BzRjmK7S"
      },
      "source": [
        "#### Attack Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzG2Lz2bmOf7"
      },
      "source": [
        "##### Invisible Character Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "yBfbMSwXYkZC"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a4023ca9fe54776a555fa20e499dd54",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Adv. Examples:   0%|          | 0/80 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sst2_targeted_experiment(InvisibleCharacterTargetedSST2NoLogitsObjective, sst2_model, [0, 1], dataset[:20], \"sst2_invisibles_targeted_nologits.pkl\", maxiter=iterations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TGTMgsooeQO"
      },
      "source": [
        "##### Homoglyph Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "mR2gCu-1ogOf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5f07f65db584e90b0a1a986e9de02fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Adv. Examples:   0%|          | 0/80 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sst2_targeted_experiment(HomoglyphTargetedSST2NoLogitsObjective, sst2_model, [0, 1], dataset[:20], \"sst2_homoglyphs_targeted_nologits.pkl\", maxiter=iterations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA5_xOr9opcJ"
      },
      "source": [
        "##### Reordering Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "yc0vzOF9otGB"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b309847b65f498fb7df9ae95e7a3706",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Adv. Examples:   0%|          | 0/80 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sst2_targeted_experiment(ReorderTargetedSST2NoLogitsObjective, sst2_model, [0, 1], dataset[:20], \"sst2_reorderings_targeted_nologits.pkl\", maxiter=iterations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skq6GKlBok7-"
      },
      "source": [
        "##### Deletion Exeriment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "_v2CBpfoomyA"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a5c16ecc936486ea8855eebe5916a24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Adv. Examples:   0%|          | 0/80 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sst2_targeted_experiment(DeletionTargetedSST2NoLogitsObjective, sst2_model, [0, 1], dataset[:20], \"sst2_deletions_targeted_nologits.pkl\", maxiter=iterations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Imperceptible",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
